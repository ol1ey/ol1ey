{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !nvcc --version\n",
        "# https://pytorch.org/get-started/locally/\n",
        "# pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n"
      ],
      "metadata": {
        "id": "4v37Tp3_dI7l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install git+https://github.com/SWivid/F5-TTS.git\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "JzP3NJkiW9Em"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB3clv5KWtQG",
        "outputId": "368e6afa-4fae-4b1c-8cad-d99b13585876",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.693 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "Word segmentation module jieba initialized.\n",
            "\n",
            "2025-01-01 19:42:12.663681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-01 19:42:12.699074: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-01 19:42:12.709469: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-01 19:42:12.732087: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-01 19:42:14.193749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Download Vocos from huggingface charactr/vocos-mel-24khz\n",
            "config.yaml: 100% 461/461 [00:00<00:00, 3.68MB/s]\n",
            "pytorch_model.bin: 100% 54.4M/54.4M [00:00<00:00, 96.3MB/s]\n",
            "model_1200000.safetensors: 100% 1.35G/1.35G [00:32<00:00, 42.1MB/s]\n",
            "model_1200000.safetensors: 100% 1.33G/1.33G [00:31<00:00, 42.1MB/s]\n",
            "\n",
            "vocab :  /usr/local/lib/python3.10/dist-packages/f5_tts/infer/examples/vocab.txt\n",
            "token :  custom\n",
            "model :  /root/.cache/huggingface/hub/models--SWivid--F5-TTS/snapshots/4dcc16f297f2ff98a17b3726b16f5de5a5e45672/F5TTS_Base/model_1200000.safetensors \n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n",
            "Starting app...\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://3a74e9027525185f3f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "config.json: 100% 1.26k/1.26k [00:00<00:00, 4.89MB/s]\n",
            "model.safetensors: 100% 1.62G/1.62G [00:37<00:00, 42.9MB/s]\n",
            "generation_config.json: 100% 3.77k/3.77k [00:00<00:00, 24.4MB/s]\n",
            "tokenizer_config.json: 100% 283k/283k [00:00<00:00, 4.09MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 5.08MB/s]\n",
            "tokenizer.json: 100% 2.71M/2.71M [00:00<00:00, 18.2MB/s]\n",
            "merges.txt: 100% 494k/494k [00:00<00:00, 43.7MB/s]\n",
            "normalizer.json: 100% 52.7k/52.7k [00:00<00:00, 136MB/s]\n",
            "added_tokens.json: 100% 34.6k/34.6k [00:00<00:00, 96.8MB/s]\n",
            "special_tokens_map.json: 100% 2.19k/2.19k [00:00<00:00, 16.4MB/s]\n",
            "preprocessor_config.json: 100% 340/340 [00:00<00:00, 2.14MB/s]\n",
            "Device set to use cuda\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\n",
            "ref_text   I don't think anyone knows who I am. \n",
            "gen_text 0 Hello guys\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py:738: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "\n",
            "ref_text   I don't think anyone knows who I am. \n",
            "gen_text 0 Hello guys. Hhhhhh u6ouyyhooy hhhuhuhuhhh hunj\n",
            "\n",
            "\n",
            "\n",
            "ref_text   I don't think anyone knows who I am. \n",
            "gen_text 0 This is not easy to do\n",
            "\n",
            "\n",
            "\n",
            "ref_text   I don't think anyone knows who I am. \n",
            "gen_text 0 This is not easy to do\n",
            "\n",
            "\n",
            "\n",
            "ref_text   I don't think anyone knows who I am. \n",
            "gen_text 0 This is not easy to do\n",
            "\n",
            "\n",
            "\n",
            "ref_text   I don't think anyone knows who I am. \n",
            "gen_text 0 This is not easy to do\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!f5-tts_infer-gradio --share"
      ]
    }
  ]
}